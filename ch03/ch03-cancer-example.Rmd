---
title: "Cancer prediction using caret (from Ch. 3 of 'Machine Learning with R')"
author: "Jesus M. Castagnetto"
date: "2014-12-27"
output: html_document
---

## Motivation

I am currently reading the book "Machine Learning with R", and also want to
learn more about the `caret` package, so I decided to replicate the kNN example
from the chapter 3 of the book using that package instead.

I will load the `caret` package, and also the `doMC` to take advantage of
parallel processing with multiple cores.

```{r}
library(caret)
library(pander)
library(doMC)
registerDoMC(cores=4)
set.seed(12345)
```

## Reading and prepa the data

As the first column in the original CSV file contains only an id, which we will
not use, we read the csv and remove it before assigning it to a data frame.

Also, we will convert the diagnosis to a factor, in a similar fashion as the
example in the book.

```{r}
wbcd <- read.csv("wisc_bc_data.csv", stringsAsFactors = FALSE)[-1]
# recode diagnosis as a factor
wbcd$diagnosis <- factor(wbcd$diagnosis, levels = c("B", "M"),
                         labels = c("Benign", "Malignant"))
str(wbcd)
```

Just to have a base measure, let's look at the the frequencies for the
diagnosis

```{r results='asis'}
frqtab <- function(x) {
    round(100*prop.table(table(x)), 1)
}
ft_orig <- frqtab(wbcd$diagnosis)
pandoc.table(ft_orig, style="grid",
             caption="Original diagnosis frequencies (%)")
```

## Modelling using the book's data partition

In the book, the first 469 rows are assigned to the training set, and
the rest to the test set.

```{r}
wbcd_train <- wbcd[1:469,]
wbcd_test <- wbcd[470:569,]
```

Justr for completeness, let's check if that data partition strategy gives
us sets with similar distributions as the original data.

```{r results='asis'}
ft_train <- frqtab(wbcd_train$diagnosis)
ft_test <- frqtab(wbcd_test$diagnosis)
ft_df <- as.data.frame(cbind(ft_orig, ft_train, ft_test))
colnames(ft_df) <- c("Original", "Training set", "Test set")
pander(ft_df, style="rmarkdown",
             caption="Comparison of diagnosis frequencies")
```

The frequencies of diagnosis in tranining set looks like the original data,
but the test set contains an overrepresentation of malignant cases.

In spite of this disparity, let's try to use kNN on the sets. We will
use repeated cross-validation, and scale the data using the `range`
method

```{r}

ctrl <- trainControl(method="repeatedcv", repeats=3)
knnFit <- train(diagnosis ~ ., data=wbcd_train, method="knn",
                trControl=ctrl, metric="Accuracy", tuneLength=20,
                preProc=c("range"))
knnFit
plot(knnFit)
```

As we can see from the results and plot, by using the accuracy metric and 
the book's data partition, the best model is the one with k=`r knnFit$finalModel$k`.

Let's use that model to compare it with the test data set.

```{r}
knnPredict <- predict(knnFit, newdata=wbcd_test)
cmat <- confusionMatrix(knnPredict, wbcd_test$diagnosis)
cmat
res <- list(model="model 1",
            tn=cmat$table[1,1],
            tp=cmat$table[2,2],
            fn=cmat$table[1,2],
            fp=cmat$table[2,1],
            k=knnFit$finalModel$k,
            metric=knnFit$metric,
            metric_value=cmat$overall[1])
```



```{r results='asis'}
# select training and test sets
# using a similar proportion 469/569 ~ 0.82425
train_index <- createDataPartition(wbcd$diagnosis, p=469/569, list=FALSE)
wbcd_train <- wbcd[train_index,]
wbcd_test <- wbcd[-train_index,]
ft_train <- frqtab(wbcd_train$diagnosis)
ft_test <- frqtab(wbcd_test$diagnosis)
ft_df <- as.data.frame(cbind(ft_orig, ft_train, ft_test))
colnames(ft_df) <- c("Original", "Training set", "Test set")
pander(ft_df, style="rmarkdown",
             caption="Comparison of diagnosis frequencies")
```

```{r}
# let's train a model using kNN, and let caret pick the best value
# for k using accuracy as the selection metric
# we preprocess the data normalizing it, using the "range" method
ctrl <- trainControl(method="repeatedcv", repeats=3)
knnFit <- train(diagnosis ~ ., data=wbcd_train, method="knn",
                trControl=ctrl, metric="Accuracy", tuneLength=20,
                preProc=c("range"))
knnFit
plot(knnFit)

# we now predict the classes for the test set
knnPredict <- predict(knnFit, newdata=wbcd_test)

# and estimate the confusion matrix to evaluate the model perfomance
cmat <- confusionMatrix(knnPredict, wbcd_test$diagnosis)
cmat
res <- rbind(res,
            list(model="model 2",
                 tn=cmat$table[1,1],
                 tp=cmat$table[2,2],
                 fn=cmat$table[1,2],
                 fp=cmat$table[2,1],
                 k=knnFit$finalModel$k,
                 metric=knnFit$metric,
                 metric_value=cmat$overall[1]))
```

```{r}
# let's try using the kappa as metric
ctrl <- trainControl(method="repeatedcv", repeats=3)
knnFit <- train(diagnosis ~ ., data=wbcd_train, method="knn",
                trControl=ctrl, metric="Kappa",
                tuneLength=21, preProc=c("range"))
knnFit
plot(knnFit)

# we now predict the classes for the test set
knnPredict <- predict(knnFit, newdata=wbcd_test)

# and estimate the confusion matrix to evaluate the model perfomance
cmat <- confusionMatrix(knnPredict, wbcd_test$diagnosis)
cmat
res <- rbind(res,
            list(model="model 3",
                 tn=cmat$table[1,1],
                 tp=cmat$table[2,2],
                 fn=cmat$table[1,2],
                 fp=cmat$table[2,1],
                 k=knnFit$finalModel$k,
                 metric=knnFit$metric,
                 metric_value=cmat$overall[1]))

```



```{r}
# let's try using the ROC as metric
ctrl <- trainControl(method="repeatedcv", repeats=3, classProbs=TRUE,
                     summaryFunction=twoClassSummary)
knnFit <- train(diagnosis ~ ., data=wbcd_train, method="knn",
                trControl=ctrl, metric="ROC",
                tuneLength=21, preProc=c("range"))
knnFit
plot(knnFit, type="S")

# we now predict the classes for the test set
knnPredict <- predict(knnFit, newdata=wbcd_test)

# and estimate the confusion matrix to evaluate the model perfomance
cmat <- confusionMatrix(knnPredict, wbcd_test$diagnosis)
cmat
res <- rbind(res,
            list(model="model 4",
                 tn=cmat$table[1,1],
                 tp=cmat$table[2,2],
                 fn=cmat$table[1,2],
                 fp=cmat$table[2,1],
                 k=knnFit$finalModel$k,
                 metric=knnFit$metric,
                 metric_value=cmat$overall[1]))

res <- data.frame(res, row.names=NULL)
```

```{r results='asis'}
pander(res, caption="Comparison of models")
```

## p = 0.85

```{r results='asis'}
# select training and test sets
# using a similar proportion 469/569 ~ 0.82425
train_index <- createDataPartition(wbcd$diagnosis, p=0.85, list=FALSE)
wbcd_train <- wbcd[train_index,]
wbcd_test <- wbcd[-train_index,]
ft_train <- frqtab(wbcd_train$diagnosis)
ft_test <- frqtab(wbcd_test$diagnosis)
ft_df <- as.data.frame(cbind(ft_orig, ft_train, ft_test))
colnames(ft_df) <- c("Original", "Training set", "Test set")
pander(ft_df, style="rmarkdown",
             caption="Comparison of diagnosis frequencies")
```

```{r}
# let's train a model using kNN, and let caret pick the best value
# for k using accuracy as the selection metric
# we preprocess the data normalizing it, using the "range" method
ctrl <- trainControl(method="repeatedcv", repeats=3)
knnFit <- train(diagnosis ~ ., data=wbcd_train, method="knn",
                trControl=ctrl, metric="Accuracy", tuneLength=20,
                preProc=c("range"))
knnFit
plot(knnFit)

# we now predict the classes for the test set
knnPredict <- predict(knnFit, newdata=wbcd_test)

# and estimate the confusion matrix to evaluate the model perfomance
cmat <- confusionMatrix(knnPredict, wbcd_test$diagnosis)
cmat
res <- rbind(res,
            list(model="model 2",
                 tn=cmat$table[1,1],
                 tp=cmat$table[2,2],
                 fn=cmat$table[1,2],
                 fp=cmat$table[2,1],
                 k=knnFit$finalModel$k,
                 metric=knnFit$metric,
                 metric_value=cmat$overall[1]))
```

```{r}
# let's try using the kappa as metric
ctrl <- trainControl(method="repeatedcv", repeats=3)
knnFit <- train(diagnosis ~ ., data=wbcd_train, method="knn",
                trControl=ctrl, metric="Kappa",
                tuneLength=21, preProc=c("range"))
knnFit
plot(knnFit)

# we now predict the classes for the test set
knnPredict <- predict(knnFit, newdata=wbcd_test)

# and estimate the confusion matrix to evaluate the model perfomance
cmat <- confusionMatrix(knnPredict, wbcd_test$diagnosis)
cmat
res <- rbind(res,
            list(model="model 3",
                 tn=cmat$table[1,1],
                 tp=cmat$table[2,2],
                 fn=cmat$table[1,2],
                 fp=cmat$table[2,1],
                 k=knnFit$finalModel$k,
                 metric=knnFit$metric,
                 metric_value=cmat$overall[1]))

```



```{r}
# let's try using the ROC as metric
ctrl <- trainControl(method="repeatedcv", repeats=3, classProbs=TRUE,
                     summaryFunction=twoClassSummary)
knnFit <- train(diagnosis ~ ., data=wbcd_train, method="knn",
                trControl=ctrl, metric="ROC",
                tuneLength=21, preProc=c("range"))
knnFit
plot(knnFit, type="S")

# we now predict the classes for the test set
knnPredict <- predict(knnFit, newdata=wbcd_test)

# and estimate the confusion matrix to evaluate the model perfomance
cmat <- confusionMatrix(knnPredict, wbcd_test$diagnosis)
cmat
res <- rbind(res,
            list(model="model 4",
                 tn=cmat$table[1,1],
                 tp=cmat$table[2,2],
                 fn=cmat$table[1,2],
                 fp=cmat$table[2,1],
                 k=knnFit$finalModel$k,
                 metric=knnFit$metric,
                 metric_value=cmat$overall[1]))

res <- data.frame(res, row.names=NULL)
```

```{r results='asis'}
pander(res, caption="Comparison of models")
```

## p = 0.9

```{r results='asis'}
# select training and test sets
# using a similar proportion 469/569 ~ 0.82425
train_index <- createDataPartition(wbcd$diagnosis, p=0.9, list=FALSE)
wbcd_train <- wbcd[train_index,]
wbcd_test <- wbcd[-train_index,]
ft_train <- frqtab(wbcd_train$diagnosis)
ft_test <- frqtab(wbcd_test$diagnosis)
ft_df <- as.data.frame(cbind(ft_orig, ft_train, ft_test))
colnames(ft_df) <- c("Original", "Training set", "Test set")
pander(ft_df, style="rmarkdown",
             caption="Comparison of diagnosis frequencies")
```

```{r}
# let's train a model using kNN, and let caret pick the best value
# for k using accuracy as the selection metric
# we preprocess the data normalizing it, using the "range" method
ctrl <- trainControl(method="repeatedcv", repeats=3)
knnFit <- train(diagnosis ~ ., data=wbcd_train, method="knn",
                trControl=ctrl, metric="Accuracy", tuneLength=20,
                preProc=c("range"))
knnFit
plot(knnFit)

# we now predict the classes for the test set
knnPredict <- predict(knnFit, newdata=wbcd_test)

# and estimate the confusion matrix to evaluate the model perfomance
cmat <- confusionMatrix(knnPredict, wbcd_test$diagnosis)
cmat
res <- rbind(res,
            list(model="model 2",
                 tn=cmat$table[1,1],
                 tp=cmat$table[2,2],
                 fn=cmat$table[1,2],
                 fp=cmat$table[2,1],
                 k=knnFit$finalModel$k,
                 metric=knnFit$metric,
                 metric_value=cmat$overall[1]))
```

```{r}
# let's try using the kappa as metric
ctrl <- trainControl(method="repeatedcv", repeats=3)
knnFit <- train(diagnosis ~ ., data=wbcd_train, method="knn",
                trControl=ctrl, metric="Kappa",
                tuneLength=21, preProc=c("range"))
knnFit
plot(knnFit)

# we now predict the classes for the test set
knnPredict <- predict(knnFit, newdata=wbcd_test)

# and estimate the confusion matrix to evaluate the model perfomance
cmat <- confusionMatrix(knnPredict, wbcd_test$diagnosis)
cmat
res <- rbind(res,
            list(model="model 3",
                 tn=cmat$table[1,1],
                 tp=cmat$table[2,2],
                 fn=cmat$table[1,2],
                 fp=cmat$table[2,1],
                 k=knnFit$finalModel$k,
                 metric=knnFit$metric,
                 metric_value=cmat$overall[1]))

```



```{r}
# let's try using the ROC as metric
ctrl <- trainControl(method="repeatedcv", repeats=3, classProbs=TRUE,
                     summaryFunction=twoClassSummary)
knnFit <- train(diagnosis ~ ., data=wbcd_train, method="knn",
                trControl=ctrl, metric="ROC",
                tuneLength=21, preProc=c("range"))
knnFit
plot(knnFit, type="S")

# we now predict the classes for the test set
knnPredict <- predict(knnFit, newdata=wbcd_test)

# and estimate the confusion matrix to evaluate the model perfomance
cmat <- confusionMatrix(knnPredict, wbcd_test$diagnosis)
cmat
res <- rbind(res,
            list(model="model 4",
                 tn=cmat$table[1,1],
                 tp=cmat$table[2,2],
                 fn=cmat$table[1,2],
                 fp=cmat$table[2,1],
                 k=knnFit$finalModel$k,
                 metric=knnFit$metric,
                 metric_value=cmat$overall[1]))

res <- data.frame(res, row.names=NULL)
```

```{r results='asis'}
pander(res, caption="Comparison of models")
```



